{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 1. Análisis de sentimiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apartado a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "file = open(\"./Datos/yelp_labelled.txt\")\n",
    "dic = {'data':[], 'target':[]}\n",
    "\n",
    "corpus = file.readlines() \n",
    "\n",
    "for i in range (len(corpus)): \n",
    "    dic.get('data').append(corpus[i].split(\"\\t\")[0]) #agrega solo las frase\n",
    "    #[0] ya que divide en una lista de dos elementos y queremos coger donde esta la frase \n",
    "    #[1] esta el numero \n",
    "    dic.get('target').append(int(corpus[i].split(\"\\t\")[1].split(\"\\n\")[0]))\n",
    "    #cogemos el numero, al hacer una nueva separacion nos devuelve una lista cons dos elementos \n",
    "    #el numero esta en la pos 0 \n",
    "\n",
    "X_train, x_test, y_train, y_test = train_test_split(dic.get('data'), dic.get('target'), test_size = 0.25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bolsa de palabras binaria con monograma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PRIMERO: \n",
    "#Obtenemos la frecuencia de palabras, mediante el diccionario estandar\n",
    "vecBM = CountVectorizer(stop_words = \"english\", binary = True, ngram_range = (1,1))\n",
    "\n",
    "train_vecBM = vecBM.fit_transform(X_train).toarray() # SOLO para conjunto de entrenamiento "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clasificador NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "# Util para clasificar documentos cortos\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión: \n",
      "0.8\n",
      "\n",
      "\n",
      "Matriz de confusion: \n",
      "[[ 97  27]\n",
      " [ 23 103]]\n"
     ]
    }
   ],
   "source": [
    "algoritmo = BernoulliNB()\n",
    "\n",
    "#Entrenamos al modelo \n",
    "algoritmo.fit(train_vecBM, y_train)\n",
    "\n",
    "#Realizo una prediccion \n",
    "\n",
    "#Importante: transform SOLO para conjunto de test \n",
    "y_pred = algoritmo.predict(vecBM.transform(x_test))\n",
    "\n",
    "matriz = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "precNB_bin_mon = metrics.accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Precisión: \")\n",
    "print(precNB_bin_mon)\n",
    "print(\"\\n\")\n",
    "print(\"Matriz de confusion: \")\n",
    "print(matriz)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La diagonal compuesta por [95, 105] corresponde con __verdaderos positivos__ y __verdaderos negativos__, es decir, hay 200 datos predichos correctamente. \n",
    "Mientras que la otra diagonal formada por [10,40], corresponden con __falsos positivos__ y __falsos negativos__ y por lo tanto hay 50 datos que no se han predecido de forma incorrecta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bolsa de palabras binaria con bigrama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "vecBB = CountVectorizer(stop_words = \"english\", binary = True, ngram_range = (1,2))\n",
    "train_vecBBarr = vecBB.fit_transform(X_train).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clasificador NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión: \n",
      "0.804\n",
      "\n",
      "\n",
      "Matriz de confusion: \n",
      "[[ 94  30]\n",
      " [ 19 107]]\n"
     ]
    }
   ],
   "source": [
    "algoritmo = BernoulliNB()\n",
    "\n",
    "#Entrenamos al modelo \n",
    "algoritmo.fit(train_vecBBarr, y_train)\n",
    "\n",
    "#Realizo una prediccion \n",
    "\n",
    "#Importante: transform SOLO para conjunto de test \n",
    "y_pred = algoritmo.predict(vecBB.transform(x_test))\n",
    "\n",
    "matriz = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "precNB_bin_bin = metrics.accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Precisión: \")\n",
    "print(precNB_bin_bin)\n",
    "print(\"\\n\")\n",
    "print(\"Matriz de confusion: \")\n",
    "print(matriz)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso usando una bolsa de palabras __binaria con bigrama__ se obtiene un precisión del __0,792__. Con 198 datos predichos de forma correcta y 52 incorrectos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bolsa de palabras TF/IDF con monograma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = CountVectorizer(stop_words = \"english\", binary = False, ngram_range = (1,1))\n",
    "\n",
    "train_vec_data = vec.fit_transform(X_train)\n",
    "\n",
    "tfidfer = TfidfTransformer()\n",
    "\n",
    "train_vecIDF = tfidfer.fit_transform(train_vec_data) # obtenemos el IDF \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vec_data = vec.transform(x_test)\n",
    "\n",
    "tes_vec_IDF = tfidfer.transform(test_vec_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión: \n",
      "0.8\n",
      "\n",
      "\n",
      "Matriz de confusion: \n",
      "[[ 97  27]\n",
      " [ 23 103]]\n"
     ]
    }
   ],
   "source": [
    "algoritmo = BernoulliNB()\n",
    "\n",
    "#Entrenamos al modelo \n",
    "algoritmo.fit(train_vecIDF, y_train)\n",
    "\n",
    "#Realizo una prediccion \n",
    "\n",
    "#Importante: transform SOLO para conjunto de test \n",
    "y_pred = algoritmo.predict(tes_vec_IDF)\n",
    "\n",
    "matriz = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "precNB_IDF_mon = metrics.accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Precisión: \")\n",
    "print(precNB_IDF_mon)\n",
    "print(\"\\n\")\n",
    "print(\"Matriz de confusion: \")\n",
    "print(matriz)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bolsa de palabras TF/IDF con bigrama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "vecBi = CountVectorizer(stop_words = \"english\", binary = False, ngram_range = (1,2))\n",
    "\n",
    "train_vec_dataBi = vecBi.fit_transform(X_train)\n",
    "\n",
    "tfidfer = TfidfTransformer()\n",
    "\n",
    "train_vecIDF_Bi = tfidfer.fit_transform(train_vec_dataBi)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vec_data_Bi = vecBi.transform(x_test)\n",
    "\n",
    "tes_vec_IDF_Bi = tfidfer.transform(test_vec_data_Bi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión: \n",
      "0.804\n",
      "\n",
      "\n",
      "Matriz de confusion: \n",
      "[[ 94  30]\n",
      " [ 19 107]]\n"
     ]
    }
   ],
   "source": [
    "algoritmo = BernoulliNB()\n",
    "\n",
    "#Entrenamos al modelo \n",
    "algoritmo.fit(train_vecIDF_Bi, y_train)\n",
    "\n",
    "#Realizo una prediccion \n",
    "\n",
    "#Importante: transform SOLO para conjunto de test \n",
    "y_pred = algoritmo.predict(tes_vec_IDF_Bi)\n",
    "\n",
    "matriz = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "precNB_IDF_bin = metrics.accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Precisión: \")\n",
    "print(precNB_IDF_bin)\n",
    "print(\"\\n\")\n",
    "print(\"Matriz de confusion: \")\n",
    "print(matriz)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Analiza la precisión y la exhaustividad de cada clasificador en cada una de las clases (opiniones positivas y negativas). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lista.count(\"item\") devuelve nummero de veces aparece item en lista\n",
    "\n",
    "#Precision: de todos los clasificados, cuantos son reales\n",
    "#reales ^ identificados por clasificador / identificados por clasificador \n",
    "\n",
    "\n",
    "\n",
    "#Exhaustividad: de todos los reales, cuantos ha recuperado\n",
    "#reales ^ identificados por clasificador / reales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Para cada clasificador, ¿tiene un comportamiento homogéneo a la hora de clasificar ambas clases? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Cuáles son las fortalezas y debilidades de cada uno de los clasificadores? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Hay algún clasificador que sea mejor que el otro en todo?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Coinciden ambos clasificadores a la hora de clasificar mejor una clase que la otra? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pinta los 8 primeros niveles del árbol de decisión y comenta lo que ves. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "plot_tree(clf, filled=True, feature_names=iris.feature_names, class_names=iris.target_names, rounded=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Qué estructura tiene el árbol? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Cómo interpretas los niveles que has pintado? ¿tienen algún sentido con respecto a la tasa de aciertos, o la precisión y exhaustividad del clasificador? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Hay nodos impuros? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Por cada clasificador identifica 2 críticas que hayan sido falsas positivas (malas críticas calificadas como buenas) y 2 críticas que han sido falsas negativas (buenas críticas clasificadas como malas). Analiza tanto su texto original, como el vector de palabras resultante (solamente los términos activos)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Por qué crees que ha fallado el clasificador en cada uno de los casos? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Se te ocurre alguna idea sobre cómo mejorar el clasificador de sentimiento?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 2. Recuperación de la información"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prueba pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holaaa"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
